{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf4262-1715-43ae-a7c3-2c36ff734b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device mps\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp testing_utils\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import FRED\n",
    "if torch.__version__[:4] == '1.14': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfc1fb-0ca5-464d-9473-fd93e685986a",
   "metadata": {},
   "source": [
    "# Comprehensive Double Helix Benchmarks on FRED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaaeb0e-4e06-4aea-8d83-f46276d89242",
   "metadata": {},
   "source": [
    "Explanation: this notebook prepares a `papermill` powered test of the toy dataset benchmarker, using the noisy double helix as our protege.\n",
    "\n",
    "Here's what it does:\n",
    "1. Start with a dict of possible parameters, each contained in a list, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728847c6-2328-4fab-b432-ffc495fe03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178875ee-005d-4311-9501-b5e85410d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'notebook' : ['05b Toy Dataset Benchmarker.ipynb'], # the notebook we are inserting these parameters into\n",
    "    'dataset_name' : ['noisy double helix'],\n",
    "    'sigma' : [1],\n",
    "    'flow_strength' : [1, 2, 5],\n",
    "    'smoothness_weight' : [0],\n",
    "    'flow_neighbor_loss_weight' : [1, 5, 10],\n",
    "    'diffdist_weight' : [1, 5, 10],\n",
    "    'num_neighbors' : [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2aa32a-72da-4866-a320-daf90654cb1c",
   "metadata": {},
   "source": [
    "2. Use this function to create a JSON file with a dictionary for each possible combination of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b2fdf-d97d-417f-9ddf-615d16b04aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import json\n",
    "import os\n",
    "\n",
    "counter = 0\n",
    "def parameters_list_from_dict(parameters_dict, outfile, filetype = \"dsq\", kernel_name = 'FREDkernel_jupyter', preamble = 'module load miniconda; conda activate FREDkernel;'):\n",
    "    ''' Given a dictionary whose values are each a list of possible values, creates a json file with one dictionary for every possible combination of values. \n",
    "        If filetype is `dsq`, then makes a txt file with each line corresponding to a job, ending in `papermill ....`.\n",
    "    '''\n",
    "    if filetype=='json':\n",
    "        with open(outfile, 'a') as f:\n",
    "                    f.write('{')\n",
    "    keys = list(parameters_dict.keys())\n",
    "    run_num = 0\n",
    "    def add_key_to_dict(little_dict, key_num):\n",
    "        if key_num == len(keys):\n",
    "            global counter\n",
    "            counter += 1\n",
    "            # write little dict to outfile\n",
    "            descriptor = f\"run{counter}\" + little_dict.__str__().replace(little_dict['notebook'],'').replace(' ','').replace(\"'\",\"\").replace(':','-').replace('{','').replace('}','').replace('.','').replace(',','_').replace('notebook-','')\n",
    "            little_dict['output_label'] = descriptor\n",
    "            with open(outfile, 'a') as f:\n",
    "                if filetype == \"json\":\n",
    "                    f.write(f'\\n\"{descriptor}\":')\n",
    "                    json.dump(little_dict,f,indent=4)\n",
    "                    f.write(',')\n",
    "                elif filetype == \"dsq\":\n",
    "                    in_notebook = little_dict['notebook']\n",
    "                    directory = 'papermilled/'+in_notebook.replace('.ipynb','')\n",
    "                    if not os.path.exists(directory):\n",
    "                        os.makedirs(directory)\n",
    "                    out_notebook =  directory + \"/\" + descriptor + '.ipynb'\n",
    "                    command = f'{preamble} papermill \"{in_notebook}\" \"{out_notebook}\" -k {kernel_name} -y \"{little_dict.__str__()}\"'\n",
    "                    f.write(f\"{command}\\n\")\n",
    "                    \n",
    "        else:\n",
    "            current_key = keys[key_num]\n",
    "            for val in parameters_dict[current_key]:\n",
    "                little_dict[current_key] = val\n",
    "                add_key_to_dict(little_dict.copy(), key_num + 1)\n",
    "    little_dict = {}\n",
    "    add_key_to_dict(little_dict, 0)\n",
    "    # delete last trailing comma, as json doesn't like this\n",
    "    if filetype == 'json':\n",
    "        with open(outfile, 'rb+') as f:\n",
    "            f.seek(-1, os.SEEK_END)\n",
    "            f.truncate()\n",
    "        with open(outfile, 'a') as f:\n",
    "            f.write('}')\n",
    "    print(f\"Created {counter} test scenarios.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be095a3-3abd-4c14-a51b-2970455054b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 27 test scenarios.\n"
     ]
    }
   ],
   "source": [
    "parameters_list_from_dict(parameters_dict, 'AUNT_HILLARY_REBORN.txt', filetype='dsq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7b9ac-5113-4db3-8619-cfe4273d28e3",
   "metadata": {},
   "source": [
    "3. Run the `nb_batch_run.py` python file, with the above json file specified as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfae12f-bb75-47fe-9862-c33288adbc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run_nb_batch.py --config_file noisy_double_helix_benchmark.json --run_mode parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc11b39-212b-42ed-a15f-de62023b5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'notebook' : '05b Toy Dataset Benchmarker.ipynb', # the notebook we are inserting these parameters into\n",
    "    'dataset_name' : 'noisy double helix',\n",
    "    'sigma' : 1,\n",
    "    'flow_strength' : 1,\n",
    "    'smoothness_weight' : 0,\n",
    "    'flow_neighbor_loss_weight' : 1,\n",
    "    'diffdist_weight' : 1,\n",
    "    'num_neighbors' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06247f4c-a568-48c6-921c-67f5ea79f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'notebook': '05b Toy Dataset Benchmarker.ipynb', 'dataset_name': 'noisy double helix', 'sigma': 1, 'flow_strength': 1, 'smoothness_weight': 0, 'flow_neighbor_loss_weight': 1, 'diffdist_weight': 1, 'num_neighbors': 5}\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_dict.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb00fe-480d-477c-ad0c-464b4b500ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_dataset_name-noisydoublehelix_sigma-1_flow_strength-1_smoothness_weight-0_flow_neighbor_loss_weight-1_diffdist_weight-1_num_neighbors-5'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_dict.__str__().replace(parameters_dict['notebook'],'').replace(' ','').replace(\"'\",\"\").replace(':','-').replace('{','').replace('}','').replace('.','').replace(',','_').replace('notebook-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f3ff5-24e4-4bae-bc51-cc064e221a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FRED]",
   "language": "python",
   "name": "conda-env-FRED-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
