{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5da15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import FRED\n",
    "if torch.__version__[:4] == '1.14': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "# sns.set_theme()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d961c",
   "metadata": {},
   "source": [
    "# 05d01 UW Method on Single Cell Datasets\n",
    "> Run the UW model on all of our toy datasets (optionally, do so many times), and produce training gifs and loss charts for each.\n",
    "\n",
    "This is set up for the popular library `papermill`, which can parameterize and execute notebooks. \n",
    "\n",
    "First, we set the notebook-wide parameters, then run the cells. Papermill will create copies of the notebook with each parameter configuration given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f7af15-4fb5-4e03-b5fd-41b2ba700142",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = \"05d01 UW Method on Single Cell Datasets.ipynb\"\n",
    "dataset_name = \"bone marrow\"\n",
    "sigma = 'automatic'\n",
    "flow_strength = 5\n",
    "smoothness_weight = 0\n",
    "flow_neighbor_loss_weight = 1\n",
    "contrastive_flow_loss_weight = 5\n",
    "diffdist_weight = 1\n",
    "num_neighbors = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d6721-0d05-496b-a9c9-350d07d051bb",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1fbfd6-d95c-499d-80fe-e3c553674ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b15d8bb54d41fe87d2949941244f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/162M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data with pcs\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "Logarithmized X.\n",
      "computing neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #277: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:07) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:03) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:05) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph (using 1/8 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a4703f55884640b77ff5335a0e90ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5780 [00:00<?, ?cells/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:26) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "computing velocity embedding\n",
      "    finished (0:00:01) --> added\n",
      "    'velocity_pca', embedded velocity vectors (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "from FRED.datasets import double_helix, directed_swiss_roll_delayed, directed_sinh_branch, rnavelo, rnavelo_pcs\n",
    "from FRED.data_processing import dataloader_from_ndarray, ManifoldWithVectorField\n",
    "from torch.utils.data import DataLoader\n",
    "import scvelo as scv\n",
    "# choose correct dataset\n",
    "if dataset_name == \"bone marrow\":\n",
    "    adata = scv.datasets.bonemarrow()\n",
    "    print(\"processing data with pcs\")\n",
    "    X, flow, labels, n_pcs = rnavelo_pcs(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5412ac92-2e2d-4d96-9ef1-6b235dc486a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5780, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36630fa-76a3-47e9-acec-fa695c6b8814",
   "metadata": {},
   "source": [
    "We have to build a directed graph from this raw data, which will serve as input to the UW algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0fbf6a-465e-4337-b94e-3d3bfa5ac5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set sigma =  4.438772\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=double, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFRED\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flashlight_affinity_matrix\n\u001b[0;32m----> 2\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mflashlight_affinity_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/gpfs/ysm/project/sumry2022/sumry2022_gt392/FRED/FRED/data_processing.py:121\u001b[0m, in \u001b[0;36mflashlight_affinity_matrix\u001b[0;34m(X, flow, k, sigma, flow_strength)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# convert back to tensors\u001b[39;00m\n\u001b[1;32m    120\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(X)\n\u001b[0;32m--> 121\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m A \u001b[38;5;241m=\u001b[39m affinity_matrix_from_pointset_to_pointset(X, X, flow, sigma\u001b[38;5;241m=\u001b[39msigma, flow_strength\u001b[38;5;241m=\u001b[39mflow_strength)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m A\n",
      "\u001b[0;31mTypeError\u001b[0m: expected TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=double, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))"
     ]
    }
   ],
   "source": [
    "from FRED.data_processing import flashlight_affinity_matrix\n",
    "A = flashlight_affinity_matrix(X, flow, k=10)\n",
    "A = A.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5330298-5e59-427d-bb3b-516279b45866",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725f6ec-d321-4a59-a351-d83111df1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def UW_directed_embedding(W, m):\n",
    "    \"\"\"\n",
    "    Replicates the velocity-embedding diffusion map from the UW paper.\n",
    "    Input W, the directed graph, and m, the number of diffusion coordinates to keep.\n",
    "    \"\"\"\n",
    "    # steps 1-6 (estimate coordinates according to diffusion map)\n",
    "    # step 1\n",
    "    S = (W + np.transpose(W))/2 # symmetric affinity matrix\n",
    "\n",
    "    # step 2\n",
    "    q = np.sum(S, axis = 1)\n",
    "    Q = np.diag(q) # degree matrix\n",
    "\n",
    "    # step 3\n",
    "    Qinv = np.linalg.inv(Q)\n",
    "    V = Qinv@S@Qinv # anisotropic normalized affinity matrix\n",
    "\n",
    "    # step 4\n",
    "    q1 = np.sum(V, axis=1)\n",
    "    Q1 = np.diag(q) # normalized degree matrix\n",
    "    Q1inv = np.linalg.inv(Q1) # \n",
    "    \n",
    "    # step 5\n",
    "    Hss = Q1inv@V # diffusion matrix (dividing affinity matrix by row sums)\n",
    "\n",
    "    # step 6\n",
    "    eig_vals, eig_vecs = np.linalg.eig(Hss)\n",
    "    idx = eig_vals.argsort()[::-1]\n",
    "    eig_vals = eig_vals[idx]\n",
    "    eig_vecs = eig_vecs[:,idx]\n",
    "\n",
    "    phi = eig_vecs[:,:(m+1)] # first (m+1) right eigenvectors\n",
    "    coords = eig_vecs[:,1:(m+1)] # first m significant right eigenvectors (coordinates of points in embedding)\n",
    "    A = np.diag(eig_vals) # diagonal matrix of (m+1) significant eigenvalues\n",
    "\n",
    "\n",
    "    # step 7-8: estimate the density\n",
    "    density = 0.1\n",
    "    \"\"\"\n",
    "    evals, evecs = scipy.linalg.eig(Hss, left = True, right = False)\n",
    "    pi = evecs[np.where(evals == 1)] # left eigenvector of Hss with eigenvalue 1\n",
    "    density = pi/sum(pi) # normalize\n",
    "    \"\"\"\n",
    "\n",
    "    # step 9-13: estimate vector field r\n",
    "    # step 9\n",
    "    p = np.sum(W, axis = 1)\n",
    "    P = np.diag(p)\n",
    "\n",
    "    # step 10\n",
    "    Pinv = np.linalg.inv(P)\n",
    "    T = Pinv@W@Pinv\n",
    "    p1 = np.sum(T, axis = 1)\n",
    "    P1 = np.diag(p1)\n",
    "\n",
    "    # step 11\n",
    "    P1inv = np.linalg.inv(P1)\n",
    "    Haa = P1@T\n",
    "\n",
    "    R = ((Haa - Hss)@phi)\n",
    "    fields = R[:,1:] # vector field components in the direction of the corresponding coordinates of the embedding\n",
    "\n",
    "    return coords, density, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d82a61-57ba-4e92-a279-d2efc6748199",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, density, velocities = UW_directed_embedding(A, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57122f-f7a7-4246-977b-851b8fdd419e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8221c-68ab-47eb-bd61-e2c574d3be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_UW_dir_emb(coords, density, fields, labels):\n",
    "    x = coords[:,0]\n",
    "    y = coords[:,1]\n",
    "    plt.scatter(x, y, c = labels)\n",
    "    # plot only a fraction of the vectors, so as not to blot everything out\n",
    "    mask = np.random.rand(len(fields)) > 0.25\n",
    "    plt.quiver(x[mask], y[mask], fields[:,0][mask], fields[:,1][mask], alpha=0.1)\n",
    "    plt.title(\"Diffusion Map\")\n",
    "visualize_UW_dir_emb(coords, density, velocities, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609f46c-02cf-4096-b2e2-65121d087b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FRED.datasets import plot_directed_2d\n",
    "plot_directed_2d(coords, velocities, labels, equal_aspect_ratio=False, title = \"UW Diffusion Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3892ee4-f2fc-4a45-9982-0522a3605ea3",
   "metadata": {},
   "source": [
    "# Qualitative analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6837e5d-222e-4af9-8aa2-98cb509ddca5",
   "metadata": {},
   "source": [
    "We combine the embedded points with their velocities in the embedding space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2c89-1292-479e-afd0-48f95219179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_points = coords\n",
    "embedded_velocities = velocities\n",
    "points_and_flows = np.concatenate([embedded_points, embedded_velocities], axis=1)\n",
    "points_and_flows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbebcf-23ff-4fd8-8ece-05cddadd8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "silhouette_points = sklearn.metrics.silhouette_score(embedded_points, labels)\n",
    "silhouette_points_and_flows = sklearn.metrics.silhouette_score(points_and_flows, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ecbd3-ad64-4c01-a99f-f7f587e732a7",
   "metadata": {},
   "source": [
    "## Nearest Neighbors Classifier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385f25b-f487-4039-a5fe-556f9bb8333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(points_and_flows, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a709e7-5e30-4962-b5a9-89358cadbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neighClass = KNeighborsClassifier(n_neighbors=3)\n",
    "neighClass.fit(X_train, y_train)\n",
    "knn_classifier_score = neighClass.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04d8db-7373-495f-8fe7-b78279f311a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"## SCORES ## \\n silhouette score w/o flows: {silhouette_points}.\\n silhouette score w/ flows:  {silhouette_points_and_flows} \\n kNN Classifier {knn_classifier_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591010b-4b74-4c92-8333-fef0c005b17d",
   "metadata": {},
   "source": [
    "# Write results to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5884a-9ea7-4ab2-852e-6fc069279f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique identifier for notebook\n",
    "import secrets\n",
    "import string\n",
    "alphabet = string.ascii_letters + string.digits\n",
    "unid = ''.join(secrets.choice(alphabet) for i in range(20))  # for a 20-character password\n",
    "unid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc99e2-9f0c-4f1a-98ea-0458036d7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "spread_name = notebook\n",
    "with open(f\"{spread_name}.csv\", 'a') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(\n",
    "        [unid, \n",
    "         sigma, \n",
    "         flow_strength, \n",
    "         flow_neighbor_loss_weight,\n",
    "         smoothness_weight, \n",
    "         diffdist_weight, \n",
    "         silhouette_points,\n",
    "         silhouette_points_and_flows,\n",
    "         knn_classifier_score\n",
    "        ]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
