{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import FRED\n",
    "if torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "# sns.set_theme()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8730c9",
   "metadata": {},
   "source": [
    "# 05c Single Cell Dataset Benchmarker\n",
    "> Run a given model on all of our toy datasets (optionally, do so many times), and produce training gifs and loss charts for each.\n",
    "\n",
    "This is set up for the popular library `papermill`, which can parameterize and execute notebooks. \n",
    "\n",
    "First, we set the notebook-wide parameters, then run the cells. Papermill will create copies of the notebook with each parameter configuration given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca641e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"notebook\":\"05c Single Cell Dataset Benchmarker.ipnb\",\n",
    "    \"dataset_name\":\"bone marrow\",\n",
    "    \"sigma\":'automatic',\n",
    "    \"flow_strength\":1,\n",
    "    \"smoothness_weight\":0,\n",
    "    \"flow_neighbor_loss_weight\":1, \n",
    "    \"diffdist_weight\":1,\n",
    "    \"num_neighbors\":10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b48937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "config = {\n",
    "    \"notebook\": \"05c Single Cell Dataset Benchmarker.ipynb\",\n",
    "    \"dataset_name\": \"bone marrow\",\n",
    "    \"sigma\": \"automatic\",\n",
    "    \"flow_strength\": 10,\n",
    "    \"smoothness_weight\": 0,\n",
    "    \"flow_neighbor_loss_weight\": 10,\n",
    "    \"diffdist_weight\": 1,\n",
    "    \"num_neighbors\": 5,\n",
    "    \"output_label\": \"run_16\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ec9f6",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f609f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized count data: X, spliced, unspliced.\n",
      "Logarithmized X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:09) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:06) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:01:20) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing velocity graph (using 1/10 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef57a7b0ee245c09f7b280f9ffeadd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5780 [00:00<?, ?cells/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:01:00) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "computing velocity embedding\n"
     ]
    }
   ],
   "source": [
    "from FRED.datasets import double_helix, directed_swiss_roll_delayed, directed_sinh_branch, rnavelo, rnavelo_pcs\n",
    "from FRED.data_processing import dataloader_from_ndarray, ManifoldWithVectorField\n",
    "from torch.utils.data import DataLoader\n",
    "import scvelo as scv\n",
    "# choose correct dataset\n",
    "if config[\"dataset_name\"] == \"bone marrow\":\n",
    "    adata = scv.datasets.bonemarrow()\n",
    "    X, flow, labels, n_pcs = rnavelo_pcs(adata)\n",
    "    \n",
    "# build dataset\n",
    "ds = ManifoldWithVectorField(X, flow, labels, sigma=config[\"sigma\"], dmap_coords_to_use=3, nbhd_strategy=\"flow neighbors\", n_neighbors=config[\"num_neighbors\"], flow_strength = config[\"flow_strength\"])\n",
    "dataloader = DataLoader(ds, batch_size=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5a60d",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381aa1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model parameters and layers\n",
    "from FRED.embed import ManifoldFlowEmbedder\n",
    "from FRED.trainers import save_embedding_visualization, visualize_points, Trainer\n",
    "title = config[\"notebook\"].replace('.ipynb','')\n",
    "MFE = ManifoldFlowEmbedder(\n",
    "            embedding_dimension=2,\n",
    "            embedder_shape=[30, 20, 10, 5, 2],\n",
    "            device=device,\n",
    "            sigma=0.5,\n",
    "            flow_strength=0.5,\n",
    "            smoothness_grid=True,\n",
    "        )\n",
    "loss_weights = {\n",
    "            \"reconstruction\": 0,\n",
    "            \"diffusion map regularization\": config[\"diffdist_weight\"],\n",
    "            \"kld\": 0,\n",
    "            \"smoothness\": config[\"smoothness_weight\"],\n",
    "            \"flow neighbor loss\": config[\"flow_neighbor_loss_weight\"],\n",
    "        }\n",
    "visualization_functions = [\n",
    "    save_embedding_visualization # just save these, for use in gif making. No visualizations otherwise, to keep it tidy.\n",
    "]\n",
    "FREDtrainer = Trainer(FE = MFE, loss_weights=loss_weights, visualization_functions = visualization_functions, device=device, title = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac942682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=FittingFRED\n",
    "FREDtrainer.fit(dataloader, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf25f0",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREDtrainer.visualize_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREDtrainer.visualize_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a12bd8",
   "metadata": {},
   "source": [
    "# Qualitative analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "silhouette = sklearn.metrics.silhouette_score(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"## SCORES ## \\n silhouette score: {silhouette} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784cbbc",
   "metadata": {},
   "source": [
    "# Write results to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique identifier for notebook\n",
    "import secrets\n",
    "import string\n",
    "alphabet = string.ascii_letters + string.digits\n",
    "unid = ''.join(secrets.choice(alphabet) for i in range(20))  # for a 20-character password\n",
    "unid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "spread_name = config[\"notebook\"].replace('.ipynb','')\n",
    "with open(f\"{spread_name}.csv\", 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([unid, config['sigma'], config['flow_strength'], config['flow_neighbor_loss_weight'],config['smoothness_weight'], config['diffdist_weight'], silhouette]) # unique id paired with silhouette score, so we can find the top performers easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42ca24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FRED]",
   "language": "python",
   "name": "conda-env-FRED-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
