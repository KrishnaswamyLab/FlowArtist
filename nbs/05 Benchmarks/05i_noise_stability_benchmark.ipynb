{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import FRED\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Stability Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single cell dataset from scvelo and get associated information\n",
    "from FRED.datasets import double_helix, directed_swiss_roll_delayed, directed_sinh_branch, rnavelo, rnavelo_pcs\n",
    "from FRED.data_processing import dataloader_from_ndarray, ManifoldWithVectorField\n",
    "from torch.utils.data import DataLoader\n",
    "import scvelo as scv\n",
    "import os\n",
    "from pathlib import Path\n",
    "dataset_name = \"pancreas\"\n",
    "# choose correct dataset\n",
    "Xpath = f\"../../data/{dataset_name}/processed/X.txt\"\n",
    "if os.path.exists(Xpath):\n",
    "    X = np.loadtxt(Xpath)\n",
    "    flow = np.loadtxt(f\"../../data/{dataset_name}/processed/flow.txt\")\n",
    "    labels = np.loadtxt(f\"../../data/{dataset_name}/processed/labels.txt\")\n",
    "    latent_time = np.loadtxt(f\"../../data/{dataset_name}/processed/latent_time.txt\")\n",
    "else:\n",
    "    if dataset_name == \"bone marrow\":\n",
    "        adata = scv.datasets.bonemarrow()\n",
    "    elif dataset_name == \"dentategyrus\":\n",
    "        adata = scv.datasets.dentategyrus()\n",
    "    elif dataset_name == \"pancreas\":\n",
    "        adata = scv.datasets.pancreas()\n",
    "    elif dataset_name == \"dentategyrus_lamanno\":\n",
    "        adata = scv.datasets.dentategyrus_lamanno()\n",
    "    print(\"processing data with pcs\")\n",
    "    X, flow, labels, n_pcs = rnavelo_pcs(adata)\n",
    "    # dynamical recovery\n",
    "    scv.tl.recover_dynamics(adata, n_jobs=1)\n",
    "    scv.tl.latent_time(adata)\n",
    "    latent_time = adata.obs['latent_time'].to_numpy()\n",
    "    # save the processed data to np txt files for ready loading in the future\n",
    "    Path(f\"../../data/{dataset_name}/processed\").mkdir(parents = True,exist_ok=True)\n",
    "    np.savetxt(f\"../../data/{dataset_name}/processed/X.txt\",X)\n",
    "    np.savetxt(f\"../../data/{dataset_name}/processed/flow.txt\",flow)\n",
    "    np.savetxt(f\"../../data/{dataset_name}/processed/labels.txt\",labels)\n",
    "    np.savetxt(f\"../../data/{dataset_name}/processed/latent_time.txt\",latent_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from FRED.data_processing import dataloader_from_ndarray_V2\n",
    "from FRED.embed import ManifoldFlowEmbedder\n",
    "from FRED.trainers import Trainer, visualize_points\n",
    "from FRED.metrics import silhouette_metric, nn_classification_metric\n",
    "import sklearn.metrics\n",
    "def noise_stability_test(\n",
    "        X, \n",
    "        flow, \n",
    "        labels, \n",
    "        noise_level = 0.1, \n",
    "        method = \"FRED\"):\n",
    "    \"\"\"\n",
    "    Tests the robustness of a method against noise added to both points and flows.\n",
    "    \"\"\"\n",
    "    X = torch.tensor(X).to(device)\n",
    "    flow = torch.tensor(flow).to(device)\n",
    "    labels = torch.tensor(labels)\n",
    "    # add noise to points\n",
    "    X_noisy = X + torch.rand_like(X)*noise_level*max(torch.linalg.norm(X,axis=1))\n",
    "    # randomly reverse some percentage of the flow\n",
    "    flow_noisy = flow\n",
    "    chosen_idxs = torch.rand(len(flow)) > noise_level\n",
    "    flow_noisy[chosen_idxs] *= -1\n",
    "    match method:\n",
    "        case \"UMAP\":\n",
    "            # Fit UMAP (proxy for scvelo)\n",
    "            reducer = umap.UMAP()\n",
    "            embedded_points = torch.tensor(reducer.fit_transform(X_noisy.cpu().numpy()))\n",
    "        case \"FRED\":\n",
    "            # Train FRED\n",
    "            # build dataloader and set up FRED\n",
    "            dataloader = dataloader_from_ndarray_V2(X_noisy,flow_noisy,labels,batch_size=256)\n",
    "            MFE = ManifoldFlowEmbedder(\n",
    "                        embedding_dimension=2,\n",
    "                        embedder_shape=[3, 4, 8, 8, 8, 4, 2],\n",
    "                        device=device,\n",
    "                        sigma=0.5,\n",
    "                        flow_strength=0.5,\n",
    "                    )\n",
    "            loss_weights = {\n",
    "                        \"distance regularization\": 100,\n",
    "                        \"contrastive loss v2\": 1,\n",
    "                        \"smoothness\": 0,\n",
    "                    }\n",
    "            visualization_functions = []\n",
    "            FREDtrainer = Trainer(FE = MFE, \n",
    "                    loss_weights=loss_weights, \n",
    "                    device=device, \n",
    "                    title=\"Noisy Embedding\", \n",
    "                    visualization_functions=visualization_functions, \n",
    "                    data_type=\"Contrastive Flow\",\n",
    "                    scheduler=None,\n",
    "                    learning_rate=1e-3)\n",
    "            FREDtrainer.fit(dataloader, n_epochs = 200)\n",
    "            FREDtrainer.visualize_embedding()\n",
    "            embedded_points = FREDtrainer.embedded_points\n",
    "        case _:\n",
    "            raise NotImplementedError(\"Must Specify UMAP or FRED\")\n",
    "    # Run metrics on points\n",
    "    silhouette_score = sklearn.metrics.silhouette_score(embedded_points, labels)\n",
    "    knn_score = nn_classification_metric(embedded_points, torch.zeros_like(embedded_points),labels)\n",
    "    print(f\"With noise level {noise_level}, {method} achieved a silhouette score of {silhouette_score} and knn score of {knn_score}\")\n",
    "    return {\"silhouette score\": silhouette_score, \"knn score\":knn_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_stability_test(X,flow,labels,noise_level = 0.1, method=\"UMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703a65ae8a954929a75b8a53fde153f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With noise level 0.1, UMAP achieved a silhouette score of 0.2762521207332611 and knn score of 0.8827868852459017\n",
      "With noise level 0.2, UMAP achieved a silhouette score of 0.1779542863368988 and knn score of 0.828688524590164\n",
      "With noise level 0.3, UMAP achieved a silhouette score of 0.11885758489370346 and knn score of 0.7295081967213115\n",
      "With noise level 0.4, UMAP achieved a silhouette score of 0.07185406982898712 and knn score of 0.6319672131147541\n",
      "With noise level 0.5, UMAP achieved a silhouette score of 0.005424517206847668 and knn score of 0.5336065573770492\n",
      "With noise level 0.6, UMAP achieved a silhouette score of -0.01959528774023056 and knn score of 0.45\n",
      "With noise level 0.7, UMAP achieved a silhouette score of -0.0642647072672844 and knn score of 0.3557377049180328\n",
      "With noise level 0.8, UMAP achieved a silhouette score of -0.06862875819206238 and knn score of 0.32049180327868854\n",
      "With noise level 0.9, UMAP achieved a silhouette score of -0.07849527150392532 and knn score of 0.25\n",
      "With noise level 1, UMAP achieved a silhouette score of -0.10564509779214859 and knn score of 0.22213114754098362\n"
     ]
    }
   ],
   "source": [
    "# test UMAP with added noise\n",
    "umap_silhouettes = []\n",
    "umap_knn_scores = []\n",
    "noises = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for ns in tqdm(noises):\n",
    "    d = noise_stability_test(X,flow,labels,noise_level = ns, method=\"UMAP\")\n",
    "    umap_silhouettes.append(d[\"silhouette score\"])\n",
    "    umap_knn_scores.append(d[\"knn score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test UMAP with added noise\n",
    "fred_silhouettes = []\n",
    "fred_knn_scores = []\n",
    "noises = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for ns in tqdm(noises):\n",
    "    d = noise_stability_test(X,flow,labels,noise_level = ns, method=\"FRED\")\n",
    "    umap_silhouettes.append(d[\"silhouette score\"])\n",
    "    umap_knn_scores.append(d[\"knn score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowartist",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
