{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scheduling\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import FRED\n",
    "if torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04a Loss Scheduling Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "# def general_scheduler(oss_weights:dict, loss_name:str, epoch:int, total_epochs:int,  c:int=1, function_type:str=\"sigmoid\"):\n",
    "#     '''\n",
    "#     Inputs\n",
    "#     loss_weights: Dictionary of loss names and their weights\n",
    "#     loss_name: the loss in the loss_weights to be scheduled\n",
    "#     epoch: current epoch\n",
    "#     total_epochs: total number of epochs that will be run\n",
    "#     c: scaler multiple for sigmoid, or slope for linear\n",
    "#     function_type: type of function for the scheduler, can be \n",
    "#         \"sigmoid\": sigmoid 1 / (1 + np.exp(c(-epoch+np.floor(total_epochs/2))))\n",
    "#         \"off\": 1 - \"sigmoid\"\n",
    "#         \"linear\": linear with slope c\n",
    "#         \"loglinear\": log linear with weight c\n",
    "    \n",
    "#     Return\n",
    "#     loss_weights dictionary with updated weight for the specified loss function at the current epoch\n",
    "#     '''\n",
    "#     if function_type == \"sigmoid\":\n",
    "#         new_weight = 1 / (1 + np.exp(-epoch+np.floor(total_epochs/2)))\n",
    "#     elif function_type == \"off\"\n",
    "#         new_weight = 1 - (1 / (1 + np.exp(-epoch+np.floor(total_epochs/2))))\n",
    "#     loss_weights[loss_name] = new_weight\n",
    "#     elif function_type == \"linear\"\n",
    "#         new_weight = c*epoch\n",
    "#     elif function_type == \"loglinear\"\n",
    "#         new_weight = np.exp(c*epoch)\n",
    "#     return loss_weights  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "# def specific_scheduler(Dictionary loss_weights, int epoch):\n",
    "#     loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"smoothness\", epoch, total_epochs=10, c=1, function_type=\"sigmoid\")\n",
    "#     # change parameters manually, however you'd like:\n",
    "#     # loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"flow neighbor loss\", epoch, total_epochs=20, c=5, function_type=\"off\")\n",
    "#     # loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"distance regularization\", epoch, total_epochs=20, c=1, function_type=\"off\")\n",
    "#     return loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class block_scheduler():\n",
    "    def __init__(\n",
    "            self,\n",
    "            epoch_to_transition,\n",
    "            loss_to_turn_on,\n",
    "            weight = 1\n",
    "    ):\n",
    "        self.epoch_number = 0\n",
    "        self.epoch_to_transition = epoch_to_transition\n",
    "        self.loss_to_turn_on = loss_to_turn_on\n",
    "        self.loss_weight = weight\n",
    "    def __call__(self,loss_weights):\n",
    "        self.epoch_number += 1\n",
    "        if self.epoch_number > self.epoch_to_transition:\n",
    "            loss_weights[self.loss_to_turn_on] = self.loss_weight\n",
    "        else:\n",
    "            if self.epoch_number > 1:\n",
    "                loss_weights[self.loss_to_turn_on] = 0\n",
    "        return loss_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
