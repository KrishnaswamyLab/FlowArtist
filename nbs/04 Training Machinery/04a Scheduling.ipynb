{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scheduling\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import FRED\n",
    "if torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04a Loss Scheduling Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def general_scheduler(Dictionary loss_weights, char loss_name, int epoch, int total_epochs, int c=1, char function_type=\"sigmoid\"):\n",
    "    '''\n",
    "    Inputs\n",
    "    loss_weights: Dictionary of loss names and their weights\n",
    "    loss_name: the loss in the loss_weights to be scheduled\n",
    "    epoch: current epoch\n",
    "    total_epochs: total number of epochs that will be run\n",
    "    c: scaler multiple for sigmoid, or slope for linear\n",
    "    function_type: type of function for the scheduler, can be \n",
    "        \"sigmoid\": sigmoid 1 / (1 + np.exp(c(-epoch+np.floor(total_epochs/2))))\n",
    "        \"off\": 1 - \"sigmoid\"\n",
    "        \"linear\": linear with slope c\n",
    "        \"loglinear\": log linear with weight c\n",
    "    \n",
    "    Return\n",
    "    loss_weights dictionary with updated weight for the specified loss function at the current epoch\n",
    "    '''\n",
    "    if function_type == \"sigmoid\":\n",
    "        new_weight = 1 / (1 + np.exp(-epoch+np.floor(total_epochs/2)))\n",
    "    elif function_type == \"off\"\n",
    "        new_weight = 1 - (1 / (1 + np.exp(-epoch+np.floor(total_epochs/2))))\n",
    "    loss_weights[loss_name] = new_weight\n",
    "    elif function_type == \"linear\"\n",
    "        new_weight = c*epoch\n",
    "    elif function_type == \"loglinear\"\n",
    "        new_weight = np.exp(c*epoch)\n",
    "    return loss_weights  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def specific_scheduler(Dictionary loss_weights, int epoch):\n",
    "    loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"smoothness\", epoch, total_epochs=10, c=1, function_type=\"sigmoid\")\n",
    "    # change parameters manually, however you'd like:\n",
    "    # loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"flow neighbor loss\", epoch, total_epochs=20, c=5, function_type=\"off\")\n",
    "    # loss_weights = sigmoid_scheduler(loss_weights, loss_name=\"distance regularization\", epoch, total_epochs=20, c=1, function_type=\"off\")\n",
    "    return loss_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
