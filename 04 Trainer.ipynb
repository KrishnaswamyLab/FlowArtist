{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device mps\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp trainers\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import FRED\n",
    "from FRED.trainers import *\n",
    "if torch.__version__[:4] == '1.13': # If using pytorch with MPS, use Apple silicon GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.has_mps else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Flow Embedder Trainers\n",
    "> Wrappers to train different variants of FRED, while producing bespoke visualizations. Useful for comparing multiple models, and also training en masse, e.g. on clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'directed_graphs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/adjourner/Projects/FRED/04 Trainer.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/FRED/04%20Trainer.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/FRED/04%20Trainer.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adjourner/Projects/FRED/04%20Trainer.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdirected_graphs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultiscale_flow_embedder\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiscaleDiffusionFlowEmbedder\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/FRED/04%20Trainer.ipynb#ch0000004?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m trange\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/FRED/04%20Trainer.ipynb#ch0000004?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'directed_graphs'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import FRED\n",
    "from tqdm import trange\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class FETrainer(object):\n",
    "    def __init__(self, X, flows, labels, device=device):\n",
    "        # super(FETrainer, self).__init__()\n",
    "        self.vizfiz = [\n",
    "            save_embedding_visualization,\n",
    "        ]\n",
    "        self.FE = MultiscaleDiffusionFlowEmbedder(\n",
    "            X=X,\n",
    "            flows=flows,\n",
    "            ts=(1, 2, 4, 8),\n",
    "            sigma_graph=0.5,\n",
    "            flow_strength_graph=5,\n",
    "            device=device,\n",
    "            use_embedding_grid=False,\n",
    "        ).to(device)\n",
    "        self.losses = None\n",
    "        self.labels = labels\n",
    "        self.title = \"Vanilla MFE\"\n",
    "        self.epochs_between_visualization = 100\n",
    "        self.total_epochs = 10000\n",
    "        self.timestamp = datetime.datetime.now().isoformat()\n",
    "        os.mkdir(f\"visualizations/{self.timestamp}\")\n",
    "\n",
    "    def fit(self):\n",
    "        num_training_runs = self.total_epochs // self.epochs_between_visualization\n",
    "        for epoch_num in trange(num_training_runs):\n",
    "            start = time.time()\n",
    "            emb_X, flow_artist, losses = self.FE.fit(\n",
    "                n_steps=self.epochs_between_visualization\n",
    "            )\n",
    "            stop = time.time()\n",
    "            title = f\"{self.timestamp}/{self.title} Epoch {epoch_num:03d}\"\n",
    "            self.visualize(emb_X, flow_artist, losses, title)\n",
    "            self.losses = collate_loss(provided_losses=losses, prior_losses=self.losses)\n",
    "        self.embedded_points = emb_X\n",
    "        self.flow_artist = flow_artist\n",
    "\n",
    "    def visualize(self, embedded_points, flow_artist, losses, title):\n",
    "        for viz_f in self.vizfiz:\n",
    "            viz_f(\n",
    "                embedded_points=embedded_points,\n",
    "                flow_artist=flow_artist,\n",
    "                losses=losses,\n",
    "                title=title,\n",
    "                labels=self.labels,\n",
    "                FE = self.FE\n",
    "            )\n",
    "\n",
    "    def training_gif(self, duration=10):\n",
    "        file_names = glob.glob(f\"visualizations/{self.timestamp}/*.jpg\")\n",
    "        file_names.sort()\n",
    "        frames = [\n",
    "            Image.open(image)\n",
    "            for image in file_names\n",
    "        ]\n",
    "        frame_one = frames[0]\n",
    "        frame_one.save(\n",
    "            f\"visualizations/{self.timestamp}/{self.title}.gif\",\n",
    "            format=\"GIF\",\n",
    "            append_images=frames,\n",
    "            save_all=True,\n",
    "            duration=duration,\n",
    "            loop=0,\n",
    "        )\n",
    "        # display in jupyter notebook\n",
    "        b64 = base64.b64encode(\n",
    "            open(f\"visualizations/{self.timestamp}/{self.title}.gif\", \"rb\").read()\n",
    "        ).decode(\"ascii\")\n",
    "        display(widgets.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))\n",
    "\n",
    "    def visualize_embedding(self):\n",
    "        visualize_points(\n",
    "            embedded_points=self.embedded_points,\n",
    "            flow_artist=self.flow_artist,\n",
    "            labels=self.labels,\n",
    "            title=self.title,\n",
    "        )\n",
    "\n",
    "    def visualize_loss(self, loss_type=\"all\"):\n",
    "        if loss_type == \"all\":\n",
    "            for key in self.losses.keys():\n",
    "                plt.plot(self.losses[key])\n",
    "            plt.legend(self.losses.keys(), loc=\"upper right\")\n",
    "            plt.title(\"loss\")\n",
    "        else:\n",
    "            plt.plot(self.losses[loss_type])\n",
    "            plt.title(loss_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyg_from_source')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
